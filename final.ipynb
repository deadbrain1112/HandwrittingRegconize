{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61bd54c-09ac-4381-885d-bf58d317effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97df896-e5b2-45fe-9f40-f2fc7b71c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('A_Z Handwritten Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0015fd-ab5f-438d-9814-25eb7fe76c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.639  0.640  0.641  \\\n",
      "0  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
      "1  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
      "2  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
      "3  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
      "4  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
      "\n",
      "   0.642  0.643  0.644  0.645  0.646  0.647  0.648  \n",
      "0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e48249-83d2-4043-b055-13d16a5fb732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_row = data.iloc[0]\n",
    "label = first_row.iloc[0]\n",
    "image_data = first_row.iloc[1:].values\n",
    "\n",
    "image = image_data.reshape((28, 28))\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Label: {chr(label + ord('A'))}\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21327553-0165-4aad-a52c-73f35be239ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\project\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.3892 - val_accuracy: 0.9672 - val_loss: 0.1191\n",
      "Epoch 2/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.1024 - val_accuracy: 0.9705 - val_loss: 0.1005\n",
      "Epoch 3/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0755 - val_accuracy: 0.9766 - val_loss: 0.0811\n",
      "Epoch 4/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0608 - val_accuracy: 0.9784 - val_loss: 0.0785\n",
      "Epoch 5/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0526 - val_accuracy: 0.9788 - val_loss: 0.0757\n",
      "Epoch 6/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0451 - val_accuracy: 0.9804 - val_loss: 0.0785\n",
      "Epoch 7/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0402 - val_accuracy: 0.9825 - val_loss: 0.0689\n",
      "Epoch 8/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0362 - val_accuracy: 0.9821 - val_loss: 0.0695\n",
      "Epoch 9/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0351 - val_accuracy: 0.9850 - val_loss: 0.0621\n",
      "Epoch 10/10\n",
      "\u001b[1m9312/9312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0315 - val_accuracy: 0.9849 - val_loss: 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Chuẩn bị dữ liệu\n",
    "data_array = data.to_numpy()\n",
    "labels = data_array[:, 0]\n",
    "images = data_array[:, 1:].reshape(-1, 28, 28) / 255\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện, validation và test\n",
    "train_images, temp_images, train_labels, temp_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(temp_images, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Xây dựng mô hình\n",
    "my_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "my_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "my_model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n",
    "\n",
    "\n",
    "my_model.save('handwritten_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21da190f-1878-4802-81a1-9d037f4f34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_classify_dictionary(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        words = [line.strip().lower() for line in file]\n",
    "    classified_dict = defaultdict(list)\n",
    "    for word in words:\n",
    "        if word:\n",
    "            classified_dict[word[0]].append(word)\n",
    "    return classified_dict\n",
    "\n",
    "# Load từ điển (thay đường dẫn thực tế)\n",
    "word_dictionary = load_and_classify_dictionary(\"dictionary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b63d42-a825-411b-8695-82af8351e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Characters(characters):\n",
    "    if not characters:\n",
    "        return None\n",
    "    char_labels = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    try:\n",
    "        characters_batch = np.stack(characters) / 255.0  # Chuẩn hóa dữ liệu\n",
    "        model_predictions = my_model.predict(characters_batch)\n",
    "        predicted_labels = np.argmax(model_predictions, axis=1)\n",
    "        return [char_labels[label] for label in predicted_labels]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d568e6b5-1cb8-4ec8-87f3-ff58445ed94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_segment_image(image):\n",
    "    # Nếu image là đường dẫn file, đọc file bằng cv2\n",
    "    if isinstance(image, str):\n",
    "        image = cv2.imread(image)\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        # Nếu image là đối tượng PIL, chuyển thành numpy array\n",
    "        grayscale_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    blurred_image = cv2.GaussianBlur(grayscale_image, (5, 5), 0)\n",
    "    binary_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 41, 25)\n",
    "\n",
    "    num_labels, labels_im = cv2.connectedComponents(binary_image, connectivity=8)\n",
    "    characters = []\n",
    "    bounding_boxes = []\n",
    "\n",
    "    for label in range(1, num_labels):\n",
    "        mask = (labels_im == label).astype(np.uint8) * 255\n",
    "        x, y, w, h = cv2.boundingRect(mask)\n",
    "        if w < 10 or h < 10:  # Bỏ qua nhiễu\n",
    "            continue\n",
    "        character = binary_image[y:y+h, x:x+w]\n",
    "        resized_character = cv2.resize(character, (18, 18))\n",
    "        padded_character = np.pad(resized_character, ((5, 5), (5, 5)), mode='constant', constant_values=0)\n",
    "        characters.append(padded_character)\n",
    "        bounding_boxes.append((x, y, w, h))\n",
    "\n",
    "    combined = list(zip(bounding_boxes, characters))\n",
    "    sorted_combined = sorted(combined, key=lambda item: item[0][0])  # Sắp xếp theo vị trí x\n",
    "    sorted_characters = [item[1] for item in sorted_combined]\n",
    "\n",
    "    # Hiển thị các ký tự đã phân đoạn\n",
    "    if len(sorted_characters) > 1:\n",
    "        fig, axs = plt.subplots(1, len(sorted_characters), figsize=(15, 5))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    \n",
    "    if len(sorted_characters) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for i, char_img in enumerate(sorted_characters):\n",
    "        axs[i].imshow(char_img, cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return sorted_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8d13aa-86f5-48cb-8571-1b0a58fdc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_words(image):\n",
    "    img_array = np.array(image.convert('L'))\n",
    "    column_sums = np.sum(img_array < 128, axis=0)\n",
    "    threshold = 50  # Ngưỡng khoảng trắng lớn\n",
    "    words_boundaries = []\n",
    "    start = 0\n",
    "\n",
    "    for i in range(1, len(column_sums)):\n",
    "        if column_sums[i] == 0 and column_sums[i-1] > 0:\n",
    "            if i - start > threshold:\n",
    "                words_boundaries.append((start, i))\n",
    "            start = i\n",
    "    if start < len(column_sums) - 1:\n",
    "        words_boundaries.append((start, len(column_sums)))\n",
    "    return words_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c4eec8b-609e-4465-9627-50c20b85aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_words(image):\n",
    "    img_array = np.array(image.convert('L'))\n",
    "    column_sums = np.sum(img_array < 128, axis=0)\n",
    "    threshold = 50  # Ngưỡng khoảng trắng lớn\n",
    "    words_boundaries = []\n",
    "    start = 0\n",
    "\n",
    "    for i in range(1, len(column_sums)):\n",
    "        if column_sums[i] == 0 and column_sums[i-1] > 0:\n",
    "            if i - start > threshold:\n",
    "                words_boundaries.append((start, i))\n",
    "            start = i\n",
    "    if start < len(column_sums) - 1:\n",
    "        words_boundaries.append((start, len(column_sums)))\n",
    "    return words_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1ea731-0a3e-4a6f-bb74-392d119dd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "\n",
    "def find_closest_word(predicted_text, first_char):\n",
    "    if not predicted_text or first_char.lower() not in word_dictionary:\n",
    "        return predicted_text\n",
    "    possible_words = word_dictionary[first_char.lower()]\n",
    "    min_distance = float('inf')\n",
    "    closest_word = predicted_text.lower()\n",
    "\n",
    "    for word in possible_words:\n",
    "        distance = Levenshtein.distance(predicted_text.lower(), word)  # Sử dụng Levenshtein.distance\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_word = word\n",
    "    return closest_word if min_distance <= 2 else predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7074000e-869e-4dd6-8e08-dec0eb439751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint(event):\n",
    "    x1, y1 = (event.x - 8), (event.y - 8)\n",
    "    x2, y2 = (event.x + 8), (event.y + 8)\n",
    "    canvas.create_oval(x1, y1, x2, y2, fill='black', width=2)\n",
    "    draw.ellipse([x1, y1, x2, y2], fill='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee9dedbd-0e49-4b56-afc8-2ac4f05af945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_canvas():\n",
    "    global canvas_image, draw\n",
    "    canvas.delete(\"all\")\n",
    "    canvas_image = Image.new(\"RGB\", (800, 800), \"white\")\n",
    "    draw = ImageDraw.Draw(canvas_image)\n",
    "    result_label.config(text=\"Predicted: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab904ae-6293-4b8f-99d0-a8d8c44e6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_character():\n",
    "    characters = preprocess_and_segment_image(canvas_image)\n",
    "    if not characters:\n",
    "        result_label.config(text=\"Predicted: No characters detected\")\n",
    "        return\n",
    "\n",
    "    # Dự đoán các ký tự\n",
    "    predictions = predict_Characters(characters)\n",
    "    if not predictions:\n",
    "        result_label.config(text=\"Predicted: Error in prediction\")\n",
    "        return\n",
    "\n",
    "    # Phát hiện các từ dựa trên khoảng trắng\n",
    "    word_boundaries = detect_words(canvas_image)\n",
    "    predicted_words = []\n",
    "\n",
    "    # Tách các ký tự thành từ dựa trên khoảng trắng\n",
    "    char_idx = 0\n",
    "    for start, end in word_boundaries:\n",
    "        word_chars = []\n",
    "        while char_idx < len(predictions):\n",
    "            x, _, _, _ = cv2.boundingRect(characters[char_idx])\n",
    "            if start <= x <= end:\n",
    "                word_chars.append(predictions[char_idx])\n",
    "                char_idx += 1\n",
    "            else:\n",
    "                break\n",
    "        if word_chars:\n",
    "            predicted_text = ''.join(word_chars)\n",
    "            corrected_word = find_closest_word(predicted_text, predicted_text[0])\n",
    "            predicted_words.append(corrected_word)\n",
    "\n",
    "    final_text = \" \".join(predicted_words)\n",
    "    result_label.config(text=f\"Predicted: {final_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f44dec1-00b6-48d8-90fe-fcc1df3fa3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "def setup_gui():\n",
    "    global window, canvas, canvas_image, draw, result_label\n",
    "\n",
    "    window = tk.Tk()\n",
    "    window.title(\"Character Recognition Board\")\n",
    "\n",
    "    canvas = tk.Canvas(window, width=800, height=800, bg='white')\n",
    "    canvas.pack()\n",
    "    canvas.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "    canvas_image = Image.new(\"RGB\", (800, 800), \"white\")\n",
    "    draw = ImageDraw.Draw(canvas_image)\n",
    "\n",
    "    predict_button = tk.Button(window, text=\"Predict\", command=predict_character)\n",
    "    predict_button.pack()\n",
    "\n",
    "    clear_button = tk.Button(window, text=\"Clear\", command=clear_canvas)\n",
    "    clear_button.pack()\n",
    "\n",
    "    result_label = tk.Label(window, text=\"Predicted: \", font=(\"Arial\", 14))\n",
    "    result_label.pack()\n",
    "\n",
    "    window.mainloop()\n",
    "\n",
    "# Chạy GUI\n",
    "setup_gui()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
